{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "import os\n",
    "import types\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.core.frame import DataFrame\n",
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getContentFromFile(filePath):\n",
    "  return open(filePath, 'r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getContent(location):\n",
    "  content = None\n",
    "  if location.startswith(\"http\"):\n",
    "    content = getContentFromUri(location)\n",
    "  else:\n",
    "    content = getContentFromFile(location)\n",
    "  if content is None:\n",
    "    raise Error(\"Could not load content for \" + location)\n",
    "  return json.loads(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "## same as what we have for json analyst\n",
    "def extract_info_text(json1, entityList):\n",
    "    for key_l1, value_l1 in json1.items():\n",
    "        if key_l1 == \"analyzeResult\":\n",
    "            for key_l2, value_l2 in value_l1.items():\n",
    "                if key_l2 == \"documentResults\":\n",
    "                    for i in range(len(value_l2)):\n",
    "                        result = value_l2[i]\n",
    "                        for key_l3, value_l3 in result.items():\n",
    "                            if key_l3 == \"fields\":\n",
    "                                result = []\n",
    "                                for key_l4, value_l4 in value_l3.items():\n",
    "#                                     print(key_l4)\n",
    "                                    for item in entityList:\n",
    "                                        \n",
    "                                        tempList = []\n",
    "                                        if key_l4 == item:\n",
    "                                            tempList = [item, value_l4['text'], value_l4['boundingBox'][0], value_l4['boundingBox'][1], value_l4['boundingBox'][2], value_l4['boundingBox'][3], value_l4['boundingBox'][4], value_l4['boundingBox'][5], value_l4['boundingBox'][6], value_l4['boundingBox'][7] ]\n",
    "                                            result.append(tempList)\n",
    "                                                    \n",
    "                                return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "## list the name of columns & targets and file names reading\n",
    "\n",
    "invoiceDirectory = \"/home/woody/桌面/2021Q6-main/Deloitte/dataset/\" ## this location supposed to be where the result of code form_recignizer_invoice is\n",
    "supportedExt = ['.json', '.jpg','.jpeg','.tif','.tiff','.png','.bmp']\n",
    "columnList=['Y','value',\"bb_loc_1\", \"bb_loc_2\", \"bb_loc_3\", \"bb_loc_4\", \"bb_loc_5\", \"bb_loc_6\", \"bb_loc_7\", \"bb_loc_8\"]\n",
    "entityList = ['CustomerAddress', 'VendorAddress', 'InvoiceId', 'PurchaseOrder']\n",
    "fileNameList = []\n",
    "for root, directories, filenames in os.walk(invoiceDirectory):\n",
    "    for invoiceFilename in filenames:\n",
    "        ext = os.path.splitext(invoiceFilename)[-1].lower()\n",
    "        invoiceFilename = invoiceDirectory + invoiceFilename\n",
    "        if ext in supportedExt:\n",
    "            fileNameList.append(invoiceFilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## load data base on file names\n",
    "\n",
    "raw_data_lists = []\n",
    "for fileName in fileNameList:\n",
    "    json_file = getContent(fileName)\n",
    "    result = extract_info_text(json_file, entityList)\n",
    "    raw_data_lists.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                 Y                                              value  \\\n",
       "0  CustomerAddress              ZEUGHOFSTRASSE 1 10997 BERLIN GERMANY   \n",
       "1        InvoiceId                                          855801065   \n",
       "2    VendorAddress  ® Langer Kornweg 34K 65451 - Kelsterbach Germa...   \n",
       "3  CustomerAddress                 Willy-Rüsch-Str. 4-10 71349 KERNEN   \n",
       "4        InvoiceId                                           80066508   \n",
       "\n",
       "   bb_loc_1  bb_loc_2  bb_loc_3  bb_loc_4  bb_loc_5  bb_loc_6  bb_loc_7  \\\n",
       "0    1.0697    1.7795    2.5096    1.7795    2.5096    2.1850    1.0697   \n",
       "1    6.4134    1.2319    7.0522    1.2319    7.0421    1.3435    6.4185   \n",
       "2    1.3891    0.4411    3.0267    0.4411    3.0267    0.9176    1.3891   \n",
       "3    0.8883    2.2147    2.2033    2.2181    2.2021    2.6909    0.8871   \n",
       "4    7.0558    2.0709    7.7411    2.0709    7.7411    2.2029    7.0558   \n",
       "\n",
       "   bb_loc_8  \n",
       "0    2.1850  \n",
       "1    1.3435  \n",
       "2    0.9176  \n",
       "3    2.6875  \n",
       "4    2.2029  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Y</th>\n      <th>value</th>\n      <th>bb_loc_1</th>\n      <th>bb_loc_2</th>\n      <th>bb_loc_3</th>\n      <th>bb_loc_4</th>\n      <th>bb_loc_5</th>\n      <th>bb_loc_6</th>\n      <th>bb_loc_7</th>\n      <th>bb_loc_8</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>CustomerAddress</td>\n      <td>ZEUGHOFSTRASSE 1 10997 BERLIN GERMANY</td>\n      <td>1.0697</td>\n      <td>1.7795</td>\n      <td>2.5096</td>\n      <td>1.7795</td>\n      <td>2.5096</td>\n      <td>2.1850</td>\n      <td>1.0697</td>\n      <td>2.1850</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>InvoiceId</td>\n      <td>855801065</td>\n      <td>6.4134</td>\n      <td>1.2319</td>\n      <td>7.0522</td>\n      <td>1.2319</td>\n      <td>7.0421</td>\n      <td>1.3435</td>\n      <td>6.4185</td>\n      <td>1.3435</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>VendorAddress</td>\n      <td>® Langer Kornweg 34K 65451 - Kelsterbach Germa...</td>\n      <td>1.3891</td>\n      <td>0.4411</td>\n      <td>3.0267</td>\n      <td>0.4411</td>\n      <td>3.0267</td>\n      <td>0.9176</td>\n      <td>1.3891</td>\n      <td>0.9176</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>CustomerAddress</td>\n      <td>Willy-Rüsch-Str. 4-10 71349 KERNEN</td>\n      <td>0.8883</td>\n      <td>2.2147</td>\n      <td>2.2033</td>\n      <td>2.2181</td>\n      <td>2.2021</td>\n      <td>2.6909</td>\n      <td>0.8871</td>\n      <td>2.6875</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>InvoiceId</td>\n      <td>80066508</td>\n      <td>7.0558</td>\n      <td>2.0709</td>\n      <td>7.7411</td>\n      <td>2.0709</td>\n      <td>7.7411</td>\n      <td>2.2029</td>\n      <td>7.0558</td>\n      <td>2.2029</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 267
    }
   ],
   "source": [
    "# transform data with only target info \n",
    "\n",
    "reshape_list = []\n",
    "for raw_data_list in raw_data_lists:\n",
    "    for item in raw_data_list:\n",
    "        reshape_list.append(item)\n",
    "df_final = pd.DataFrame(reshape_list, columns=columnList)\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bert function for word embedding \n",
    "\n",
    "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "pt_model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "sentences_List = []\n",
    "for sentence in df_final.value:\n",
    "    inputs = tokenizer(sentence)\n",
    "    sentences_List.append(inputs['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "51\n"
     ]
    }
   ],
   "source": [
    "# sentences_List\n",
    "def find_max_list(list):\n",
    "    list_len = [len(i) for i in list]\n",
    "    return max(list_len)\n",
    "print(find_max_list(sentences_List))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the length for embedding results\n",
    "length_long_sentence = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 padding for the result with length = 'length_long_sentence'\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "padded_sentences = pad_sequences(sentences_List, length_long_sentence, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transpose the matrix for easier adding inside dataframe\n",
    "padded_sentences = np.transpose(padded_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name the columns\n",
    "Columns_vectorized_list = ['column_01', 'column_02', 'column_03', 'column_04', 'column_05', 'column_06', 'column_07', 'column_08', 'column_09', 'column_10',\n",
    "'column_11', 'column_12', 'column_13', 'column_14', 'column_15', 'column_16', 'column_17', 'column_18', 'column_19', 'column_20',\n",
    "'column_21', 'column_22', 'column_23', 'column_24', 'column_25', 'column_26', 'column_27', 'column_28', 'column_29', 'column_30',\n",
    "'column_31', 'column_32', 'column_33', 'column_34', 'column_35', 'column_36', 'column_37', 'column_38', 'column_39', 'column_40',\n",
    "'column_41', 'column_42', 'column_43', 'column_44', 'column_45', 'column_46', 'column_47', 'column_48', 'column_49', 'column_50',\n",
    "'column_51', 'column_52', 'column_53', 'column_54', 'column_55', 'column_56', 'column_57', 'column_58', 'column_59', 'column_60']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "78\n"
     ]
    }
   ],
   "source": [
    "temp_list = padded_sentences.tolist()\n",
    "# stand for the number of examples we have after transposation\n",
    "print(len(temp_list[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(temp_list)):\n",
    "    df_final[Columns_vectorized_list[i]] = temp_list[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, make_response\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io\n",
    "import re\n",
    "import nltk\n",
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df, columnList):\n",
    "    \"\"\"Preprocess training dataframe.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: pandas.DataFrame\n",
    "        dataframe containing 'movie_id', 'synopsis' and 'genres' columns\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df: pandas.DataFrame\n",
    "        dataframe with labels als 0/1 columns\n",
    "    \"\"\"\n",
    "    # df = df[columnList]\n",
    "    for i in df.index:\n",
    "        Ys = df.loc[i, 'Y'].split(' ')\n",
    "        for Y in Ys:\n",
    "            if not (Y in df.columns):\n",
    "                df[Y] = 0\n",
    "            df.loc[i, Y] = 1\n",
    "    del df['Y']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = preprocess(df_final, columnList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                               value  bb_loc_1  bb_loc_2  \\\n",
       "0              ZEUGHOFSTRASSE 1 10997 BERLIN GERMANY    1.0697    1.7795   \n",
       "1                                          855801065    6.4134    1.2319   \n",
       "2  ® Langer Kornweg 34K 65451 - Kelsterbach Germa...    1.3891    0.4411   \n",
       "3                 Willy-Rüsch-Str. 4-10 71349 KERNEN    0.8883    2.2147   \n",
       "4                                           80066508    7.0558    2.0709   \n",
       "\n",
       "   bb_loc_3  bb_loc_4  bb_loc_5  bb_loc_6  bb_loc_7  bb_loc_8  column_01  ...  \\\n",
       "0    2.5096    1.7795    2.5096    2.1850    1.0697    2.1850        101  ...   \n",
       "1    7.0522    1.2319    7.0421    1.3435    6.4185    1.3435        101  ...   \n",
       "2    3.0267    0.4411    3.0267    0.9176    1.3891    0.9176        101  ...   \n",
       "3    2.2033    2.2181    2.2021    2.6909    0.8871    2.6875        101  ...   \n",
       "4    7.7411    2.0709    7.7411    2.2029    7.0558    2.2029        101  ...   \n",
       "\n",
       "   column_55  column_56  column_57  column_58  column_59  column_60  \\\n",
       "0          0          0          0          0          0          0   \n",
       "1          0          0          0          0          0          0   \n",
       "2          0          0          0          0          0          0   \n",
       "3          0          0          0          0          0          0   \n",
       "4          0          0          0          0          0          0   \n",
       "\n",
       "   CustomerAddress  InvoiceId  VendorAddress  PurchaseOrder  \n",
       "0                1          0              0              0  \n",
       "1                0          1              0              0  \n",
       "2                0          0              1              0  \n",
       "3                1          0              0              0  \n",
       "4                0          1              0              0  \n",
       "\n",
       "[5 rows x 73 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>value</th>\n      <th>bb_loc_1</th>\n      <th>bb_loc_2</th>\n      <th>bb_loc_3</th>\n      <th>bb_loc_4</th>\n      <th>bb_loc_5</th>\n      <th>bb_loc_6</th>\n      <th>bb_loc_7</th>\n      <th>bb_loc_8</th>\n      <th>column_01</th>\n      <th>...</th>\n      <th>column_55</th>\n      <th>column_56</th>\n      <th>column_57</th>\n      <th>column_58</th>\n      <th>column_59</th>\n      <th>column_60</th>\n      <th>CustomerAddress</th>\n      <th>InvoiceId</th>\n      <th>VendorAddress</th>\n      <th>PurchaseOrder</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ZEUGHOFSTRASSE 1 10997 BERLIN GERMANY</td>\n      <td>1.0697</td>\n      <td>1.7795</td>\n      <td>2.5096</td>\n      <td>1.7795</td>\n      <td>2.5096</td>\n      <td>2.1850</td>\n      <td>1.0697</td>\n      <td>2.1850</td>\n      <td>101</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>855801065</td>\n      <td>6.4134</td>\n      <td>1.2319</td>\n      <td>7.0522</td>\n      <td>1.2319</td>\n      <td>7.0421</td>\n      <td>1.3435</td>\n      <td>6.4185</td>\n      <td>1.3435</td>\n      <td>101</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>® Langer Kornweg 34K 65451 - Kelsterbach Germa...</td>\n      <td>1.3891</td>\n      <td>0.4411</td>\n      <td>3.0267</td>\n      <td>0.4411</td>\n      <td>3.0267</td>\n      <td>0.9176</td>\n      <td>1.3891</td>\n      <td>0.9176</td>\n      <td>101</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Willy-Rüsch-Str. 4-10 71349 KERNEN</td>\n      <td>0.8883</td>\n      <td>2.2147</td>\n      <td>2.2033</td>\n      <td>2.2181</td>\n      <td>2.2021</td>\n      <td>2.6909</td>\n      <td>0.8871</td>\n      <td>2.6875</td>\n      <td>101</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>80066508</td>\n      <td>7.0558</td>\n      <td>2.0709</td>\n      <td>7.7411</td>\n      <td>2.0709</td>\n      <td>7.7411</td>\n      <td>2.2029</td>\n      <td>7.0558</td>\n      <td>2.2029</td>\n      <td>101</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 73 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 279
    }
   ],
   "source": [
    "labels = list(df_final.columns[69:])\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "## last time data preparation\n",
    "\n",
    "x = df_final.copy()\n",
    "y = df_final[labels]\n",
    "for i in range(len(labels)):\n",
    "    del x[labels[i]]\n",
    "del x['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data split for training and testing/evaluating\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/woody/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "the accuracy on test dataset 0.7692307692307693\n",
      "/home/woody/anaconda3/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "OneVsRest_model = OneVsRestClassifier(\n",
    "    # LogisticRegression(C=1.8, solver=\"lbfgs\", penalty=\"l2\", max_iter=250)\n",
    "    XGBClassifier(eval_metric='mlogloss')\n",
    ")\n",
    "OneVsRest_model.fit(x_train, y_train)\n",
    "predictions = OneVsRest_model.predict(x_test)\n",
    "\n",
    "print(\"the accuracy on test dataset\", accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "## some thoughts for future work:\n",
    "# 1) there might be some link between different features, we can train a simple NN to solve the multicollinearity issue\n",
    "# 2) more detailed parameter tuning for XGBoost and also try other algorithms, I tried SVM, LR and decision tree. We can try more models\n",
    "# 3) Maybe we can try stacking models to improve the accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python388jvsc74a57bd07a9d0b6474e7d18f529cd01f039bbeaa136dc7673c5493036ea44090f1dc286b",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}